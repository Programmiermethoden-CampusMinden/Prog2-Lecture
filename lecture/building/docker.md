# EinfÃ¼hrung in Docker

> [!IMPORTANT]
>
> <details open>
>
> <summary><strong>ğŸ¯ TL;DR</strong></summary>
>
> Container sind im Gegensatz zu herkÃ¶mmlichen VMs eine schlanke
> VirtualisierungslÃ¶sung. Dabei laufen die Prozesse direkt im Kernel des
> Host-Betriebssystems, aber abgeschottet von den anderen Prozessen
> durch Linux-Techniken wie `cgroups` und `namespaces` (unter Windows
> kommt dafÃ¼r der WSL2 zum Einsatz, unter macOS wird eine kleine
> Virtualisierung genutzt).
>
> Container sind sehr nÃ¼tzlich, wenn man an mehreren Stellen eine
> identische Arbeitsumgebung benÃ¶tigt. Man kann dabei entweder die
> Images (fertige Dateien) oder die Dockerfiles (Anweisungen zum
> Erzeugen eines Images) im Projekt verteilen. TatsÃ¤chlich ist es nicht
> unÃ¼blich, ein Dockerfile in das Projekt-Repo mit einzuchecken.
>
> Durch Container hat man allerdings im Gegensatz zu herkÃ¶mmlichen VMs
> keinen Sicherheitsgewinn, da die im Container laufende Software ja
> direkt auf dem Host-Betriebssystem ausgefÃ¼hrt wird.
>
> Es gibt auf DockerHub fertige Images, die man sich ziehen und starten
> kann. Ein solches gestartetes Image nennt sich dann Container und
> enthÃ¤lt beispielsweise Dateien, die in den Container gemountet oder
> kopiert werden. Man kann auch eigene Images bauen, indem man eine
> entsprechende Konfiguration (Dockerfile) schreibt. Jeder Befehl bei
> der Erstellung eines Images erzeugt einen neuen Layer, die sich
> dadurch mehrere Images teilen kÃ¶nnen.
>
> In der Konfiguration einer Gitlab-CI-Pipeline kann man mit `image` ein
> Docker-Image angeben, welches dann in der Pipeline genutzt wird.
>
> VSCode kann Ã¼ber das Remote-Plugin sich (u.a.) mit Containern
> verbinden und dann im Container arbeiten (editieren, compilieren,
> debuggen, testen, â€¦).
>
> In dieser kurzen Einheit kann ich Ihnen nur einen ersten Einstieg in
> das Thema geben. Wir haben uns beispielsweise nicht Docker Compose
> oder Kubernetes angeschaut, und auch die Themen Netzwerk (zwischen
> Containern oder zwischen Containern und anderen Rechnern) und Volumes
> habe ich auÃŸen vor gelassen. Dennoch kommt man in der Praxis bereits
> mit den hier vermittelten Basiskenntnissen erstaunlich weit â€¦
> </details>

> [!TIP]
>
> <details open>
>
> <summary><strong>ğŸ¦ Videos</strong></summary>
>
> - [VL EinfÃ¼hrung in Docker](https://youtu.be/yERVMfUAano)
> - [Demo Container in der Konsole](https://youtu.be/LE_QcHqUg9Y)
> - [Demo GitLab CI/CD und Docker](https://youtu.be/3Tj3lhcoKro)
> - [Demo GitHub Actions und Docker](https://youtu.be/jrxoax2fPRI)
> - [Demo VSCode und Docker](https://youtu.be/Rs1W_rXkoNM)
>
> </details>

## Motivation CI/CD: WFM (*Works For Me*)

<picture><source media="(prefers-color-scheme: light)" srcset="images/ci_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/ci_dark.png"><img src="images/ci.png" width="60%"></picture>

Auf dem CI-Server muss man eine Arbeitsumgebung konfigurieren und
bereitstellen, fÃ¼r Java-basierte Projekte muss beispielsweise ein JDK
existieren und man benÃ¶tigt Tools wie Maven oder Gradle, um die
Buildskripte auszufÃ¼hren. Je nach Projekt braucht man dann noch weitere
Tools und Bibliotheken. Diese Konfigurationen sind unabhÃ¤ngig vom
CI-Server und werden Ã¼blicherweise nicht direkt installiert, sondern
Ã¼ber eine Virtualisierung bereitgestellt.

Selbst wenn man keine CI-Pipelines einsetzt, hat man in Projekten mit
mehreren beteiligten Personen hÃ¤ufig das Problem â€œ*WFM*â€ (â€œworks for
meâ€). Jeder Entwickler hat sich auf ihrem Rechner eine
Entwicklungsumgebung aufgesetzt und nutzt in der Regel seine bevorzugte
IDE oder sogar unterschiedliche JDK-Versionen â€¦ Dadurch kann es schnell
passieren, dass Probleme oder Fehler auftreten, die sich nicht von allen
Beteiligten immer nachvollziehen lassen. Hier wÃ¤re eine einheitliche
Entwicklungsumgebung sinnvoll, die in einer â€œschlankenâ€ Virtualisierung
bereitgestellt wird.

Als Entwickler kann man zeitgleich in verschiedenen Projekten beteiligt
sein, die unterschiedliche Anforderungen an die Entwicklungstools mit
sich bringen. Es kÃ¶nnte beispielsweise passieren, dass man zeitgleich
drei bestimmte Python-Versionen benÃ¶tigt. In den meisten FÃ¤llen schafft
man es (mit ein wenig Aufwand), diese Tools nebeneinander zu
installieren. Oft ist das in der Praxis aber schwierig und
fehleranfÃ¤llig.

In diesen FÃ¤llen kann eine Virtualisierung helfen.

## Virtualisierung: Container vs.Â VM

<picture><source media="(prefers-color-scheme: light)" srcset="images/virtualisierung_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/virtualisierung_dark.png"><img src="images/virtualisierung.png" width="50%"></picture>

Wenn man Ã¼ber Virtualisierung auf dem Desktop spricht, kann man grob
zwei Varianten unterscheiden. In beiden FÃ¤llen ist die Basis die
Hardware (Laptop, Desktop-Rechner) und das darauf laufende (Host-)
Betriebssystem (Linux, FreeBSD, macOS, Windows, â€¦). Darauf lÃ¤uft dann
wiederum die Virtualisierung.

Im rechten Bild wird eine herkÃ¶mmliche Virtualisierung mit virtuellen
Maschinen (*VM*) dargestellt. Dabei wird in der VM ein komplettes
Betriebssystem (das â€œGast-Betriebssystemâ€) installiert und darin lÃ¤uft
dann die gewÃ¼nschte Anwendung. Die Virtualisierung (VirtualBox, VMware,
â€¦) lÃ¤uft dabei als Anwendung auf dem Host-Betriebssystem und stellt dem
Gast-Betriebssystem in der VM einen Rechner mit CPU, RAM, â€¦ zur
VerfÃ¼gung und Ã¼bersetzt die Systemaufrufe in der VM in die
entsprechenden Aufrufe im Host-Betriebssystem. Dies benÃ¶tigt in der
Regel entsprechende Ressourcen: Durch das komplette Betriebssystem in
der VM ist eine VM (die als Datei im Filesystem des Host-Betriebssystems
liegt) oft mehrere 10GB groÃŸ. FÃ¼r die Ãœbersetzung werden zusÃ¤tzlich
Hardwareressourcen benÃ¶tigt, d.h. hier gehen CPU-Zyklen und RAM
â€œverlorenâ€ â€¦ Das Starten einer VM dauert entsprechend lange, da hier ein
komplettes Betriebssystem hochgefahren werden muss. DafÃ¼r sind die
Prozesse in einer VM relativ stark vom Host-Betriebssystem abgekapselt,
so dass man hier von einer â€œSandboxâ€ sprechen kann: Viren o.Ã¤. kÃ¶nnen
nicht so leicht aus einer VM â€œausbrechenâ€ und auf das
Host-Betriebssystem zugreifen (quasi nur Ã¼ber LÃ¼cken im
Gast-Betriebssystem kombiniert mit LÃ¼cken in der
Virtualisierungssoftware).

Im linken Bild ist eine schlanke Virtualisierung auf Containerbasis
dargestellt. Die Anwendungen laufen direkt als Prozesse im
Host-Betriebssystem, ein Gast-Betriebssystem ist nicht notwendig. Durch
den geschickten Einsatz von `namespaces` und `cgroups` und anderen in
Linux und FreeBSD verfÃ¼gbaren Techniken werden die Prozesse
abgeschottet, d.h. der im Container laufende Prozess â€œsiehtâ€ die anderen
Prozesse des Hosts nicht. Die Erstellung und Steuerung der Container
Ã¼bernimmt hier beispielsweise Docker. Die Container sind dabei auch
wieder Dateien im Host-Filesystem. Dadurch benÃ¶tigen Container
wesentlich weniger Platz als herkÃ¶mmliche VMs, der Start einer Anwendung
geht deutlich schneller und die Hardwareressourcen (CPU, RAM, â€¦) werden
effizient genutzt. Nachteilig ist, dass hier in der Regel ein Linux-Host
benÃ¶tigt wird (fÃ¼r Windows wird mittlerweile der Linux-Layer (*WSL*)
genutzt; fÃ¼r macOS wurde bisher eine Linux-VM im Hintergrund
hochgefahren, mittlerweile wird aber eine eigene schlanke
Virtualisierung eingesetzt). AuÃŸerdem steht im Container Ã¼blicherweise
kein graphisches Benutzerinterface zur VerfÃ¼gung. Da die Prozesse direkt
im Host-Betriebssystem laufen, stellen Container keine
Sicherheitsschicht (â€œSandboxenâ€) dar!

In allen FÃ¤llen muss die Hardwarearchitektur beachtet werden: Auf einer
Intel-Maschine kÃ¶nnen normalerweise keine VMs/Container basierend auf
ARM-Architektur ausgefÃ¼hrt werden und umgekehrt.

## Getting started

- DockerHub: fertige Images =\>
  [hub.docker.com/search](https://hub.docker.com/search?q=&type=image)

<!-- -->

- Image downloaden: `docker pull <IMAGE>`
- Image starten: `docker run <IMAGE>`

### Begriffe

- **Docker-File**: Beschreibungsdatei, wie Docker ein Image erzeugen
  soll.
- **Image**: EnthÃ¤lt die Dinge, die lt. dem Docker-File in das Image
  gepackt werden sollen. Kann gestartet werden und erzeugt damit einen
  Container.
- **Container**: Ein laufendes Images (genauer: eine laufende Instanz
  eines Images). Kann dann auch zusÃ¤tzliche Daten enthalten.

### Beispiele

    docker pull debian:stable-slim
    docker run  --rm -it  debian:stable-slim  /bin/sh

`debian` ist ein fertiges Images, welches Ã¼ber DockerHub bereit gestellt
wird. Mit dem Postfix `stable-slim` wird eine bestimmte Version
angesprochen.

Mit `docker run debian:stable-slim` startet man das Image, es wird ein
Container erzeugt. Dieser enthÃ¤lt den aktuellen Datenstand, d.h. wenn
man im Image eine Datei anlegt, wÃ¤re diese dann im Container enthalten.

Mit der Option `--rm` wird der Container nach Beendigung automatisch
wieder gelÃ¶scht. Da jeder Aufruf von `docker run <IMAGE>` einen neuen
Container erzeugt, wÃ¼rden sich sonst recht schnell viele Container auf
dem Dateisystem des Hosts ansammeln, die man dann manuell aufrÃ¤umen
mÃ¼sste. Man kann aber einen beendeten Container auch erneut laufen
lassen â€¦ (vgl. Dokumentation von `docker`). Mit der Option `--rm` sind
aber auch im Container angelegte Daten wieder weg! Mit der Option `-it`
wird der Container interaktiv gestartet und man landet in einer Shell.

Bei der Definition eines Images kann ein â€œ*Entry Point*â€ definiert
werden, d.h. ein Programm, welches automatisch beim Start des Container
ausgefÃ¼hrt wird. HÃ¤ufig erlauben Images aber auch, beim Start ein
bestimmtes auszufÃ¼hrendes Programm anzugeben. Im obigen Beispiel ist das
`/bin/sh`, also eine Shell â€¦

    docker pull openjdk:latest
    docker run  --rm  -v "$PWD":/data -w /data  openjdk:latest  javac Hello.java
    docker run  --rm  -v "$PWD":/data -w /data  openjdk:latest  java Hello

Auch fÃ¼r Java gibt es vordefinierte Images mit einem JDK. Das Tag
â€œ`latest`â€ zeigt dabei auf die letzte stabile Version des
`openjdk`-Images. Ãœblicherweise wird â€œ`latest`â€ von den Entwicklern
immer wieder weiter geschoben, d.h. auch bei anderen Images gibt es ein
â€œ`latest`â€-Tag. Gleichzeitig ist es die Default-Einstellung fÃ¼r die
Docker-Befehle, d.h. es kann auch weggelassen werden:
`docker run openjdk:latest` und `docker run openjdk` sind gleichwertig.
Alternativ kann man hier auch hier wieder eine konkrete Version angeben.

Ãœber die Option `-v` wird ein Ordner auf dem Host (hier durch `"$PWD"`
dynamisch ermittelt) in den Container eingebunden (â€œgemountetâ€), hier
auf den Ordner `/data`. Dort sind dann die Dateien sichtbar, die im
Ordner `"$PWD"` enthalten sind. Ãœber die Option `-w` kann ein
Arbeitsverzeichnis definiert werden.

Mit `javac Hello.java` wird `javac` im Container aufgerufen auf der
Datei `/data/Hello.java` im Container, d.h. die Datei `Hello.java`, die
im aktuellen Ordner des Hosts liegt (und in den Container gemountet
wurde). Das Ergebnis (`Hello.class`) wird ebenfalls in den Ordner
`/data/` im Container geschrieben und erscheint dann im
Arbeitsverzeichnis auf dem Host â€¦ Analog kann dann mit `java Hello` die
Klasse ausgefÃ¼hrt werden.

<p align="right"><a href="https://youtu.be/LE_QcHqUg9Y">Demo: Container in der Konsole</a></p>

## Images selbst definieren

``` docker
FROM debian:stable-slim

ARG USERNAME=pandoc
ARG USER_UID=1000
ARG USER_GID=1000

RUN apt-get update && apt-get install -y --no-install-recommends            \
        apt-utils bash wget make graphviz biber                             \
        texlive-base texlive-plain-generic texlive-latex-base               \
    #
    && groupadd --gid $USER_GID $USERNAME                                   \
    && useradd -s /bin/bash --uid $USER_UID --gid $USER_GID -m $USERNAME    \
    #
    && apt-get autoremove -y && apt-get clean -y && rm -rf /var/lib/apt/lists/*

WORKDIR /pandoc
USER $USERNAME
```

`docker build -t <NAME> -f <DOCKERFILE> .`

`FROM` gibt die Basis an, d.h. hier ein Image von Debian in der Variante
`stable-slim`, d.h. das ist der Basis-Layer fÃ¼r das zu bauende
Docker-Image.

Ãœber `ARG` werden hier Variablen gesetzt.

`RUN` ist der Befehl, der im Image (hier Debian) ausgefÃ¼hrt wird und
einen neuen Layer hinzufÃ¼gt. In diesen Layer werden alle Dateien
eingefÃ¼gt, die bei der AusfÃ¼hrung des Befehls erzeugt oder angelegt
werden. Hier im Beispiel wird das Debian-Tool `apt-get` gestartet und
weitere Debian-Pakete installiert.

Da jeder `RUN`-Befehl einen neuen Layer anlegt, werden die restlichen
Konfigurationen ebenfalls in diesem Lauf durchgefÃ¼hrt. Insbesondere wird
ein nicht-Root-User angelegt, der von der UID und GID dem Default-User
in Linux entspricht. Die gemounteten Dateien haben die selben Rechte wie
auf dem Host, und durch die Ãœbereinstimmung von UID/GID sind die Dateien
problemlos zugreifbar und man muss nicht mit dem Root-User arbeiten
(dies wird aus offensichtlichen GrÃ¼nden als Anti-Pattern angesehen).
Bevor der `RUN`-Lauf abgeschlossen wird, werden alle temporÃ¤ren und
spÃ¤ter nicht benÃ¶tigten Dateien von `apt-get` entfernt, damit diese
nicht Bestandteil des Layers werden.

Mit `WORKDIR` und `USER` wird das Arbeitsverzeichnis gesetzt und auf den
angegebenen User umgeschaltet. Damit muss der User nicht mehr beim
Aufruf von auÃŸen gesetzt werden.

Ãœber `docker build -t <NAME> -f <DOCKERFILE> .` wird aus dem angegebenen
Dockerfile und dem Inhalt des aktuellen Ordners (â€œ`.`â€) ein neues Image
erzeugt und mit dem angegebenen Namen benannt.

**Hinweis zum Umgang mit Containern und Updates**: Bei der Erstellung
eines Images sind bestimmte Softwareversionen Teil des Images geworden.
Man kann prinzipiell in einem Container die Software aktualisieren, aber
dies geht in dem Moment wieder verloren, wo der Container beendet und
gelÃ¶scht wird. AuÃŸerdem widerspricht dies dem Gedanken, dass mehrere
Personen mit dem selben Image/Container arbeiten und damit auch die
selben VersionsstÃ¤nde haben. In der Praxis lÃ¶scht man deshalb das alte
Image einfach und erstellt ein neues, welches dann die aktualisierte
Software enthÃ¤lt.

<p align="right"><a href="https://github.com/Programmiermethoden-CampusMinden/Prog2-Lecture/blob/master/lecture/building/src/docker/debian-latex.df">Beispiel: debian-latex.df</a></p>

## CI-Pipeline (GitLab)

``` yaml
default:
    image: openjdk:17

job1:
    stage: build
    script:
        - java -version
        - javac Hello.java
        - java Hello
        - ls -lags
```

In den Gitlab-CI-Pipelines (analog wie in den GitHub-Actions) kann man
Docker-Container fÃ¼r die AusfÃ¼hrung der Pipeline nutzen.

Mit `image: openjdk:17` wird das Docker-Image `openjdk:17` vom DockerHub
geladen und durch den Runner fÃ¼r die Stages als Container ausgefÃ¼hrt.
Die Aktionen im `script`-Teil, wie beispielsweise `javac Hello.java`
werden vom Runner an die Standard-Eingabe der Shell des Containers
gesendet. Im Prinzip entspricht das dem Aufruf auf dem lokalen Rechner:
`docker run openjdk:17 javac Hello.java`.

<p align="right"><a href="https://youtu.be/3Tj3lhcoKro">Demo: GitLab CI/CD und Docker</a></p>

## CI-Pipeline (GitHub)

``` yaml
name: demo
on:
    push:
        branches: [master]
    workflow_dispatch:

jobs:
    job1:
        runs-on: ubuntu-latest
        container: docker://openjdk:17
        steps:
            - uses: actions/checkout@v6
            - run: java -version
            - run: javac Hello.java
            - run: java Hello
            - run: ls -lags
```

https://stackoverflow.com/questions/71283311/run-github-workflow-on-docker-image-with-a-dockerfile
https://docs.github.com/en/actions/using-jobs/running-jobs-in-a-container

In den GitHub-Actions kann man Docker-Container fÃ¼r die AusfÃ¼hrung der
Pipeline nutzen.

Mit `docker://openjdk:17` wird das Docker-Image `openjdk:17` vom
DockerHub geladen und auf dem Ubuntu-Runner als Container ausgefÃ¼hrt.
Die Aktionen im `steps`-Teil, wie beispielsweise `javac Hello.java`
werden vom Runner an die Standard-Eingabe der Shell des Containers
gesendet. Im Prinzip entspricht das dem Aufruf auf dem lokalen Rechner:
`docker run openjdk:17 javac Hello.java`.

<p align="right"><a href="https://youtu.be/jrxoax2fPRI">Demo: GitHub Actions und Docker</a></p>

## VSCode und das Plugin â€œRemote - Containersâ€

<picture><source media="(prefers-color-scheme: light)" srcset="images/vscode-remote_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/vscode-remote_dark.png"><img src="images/vscode-remote.png" width="80%"></picture>

1.  VSCode (Host): Plugin â€œRemote - Containersâ€ installieren
2.  Docker (Host): Container starten mit Workspace gemountet
3.  VSCode (Host): Attach to Container =\> neues Fenster (Container)
4.  VSCode (Container): Plugin â€œJava Extension Packâ€ installieren
5.  VSCode (Container): Dateien editieren, kompilieren, debuggen, â€¦

Mit Visual Studio Code (VSC) kann man Ã¼ber SSH oder in einem Container
arbeiten. Dazu installiert man sich VSC lokal auf dem Host und
installiert dort das Plugin â€œRemote - Containersâ€. VSC kann darÃ¼ber
vordefinierte Docker-Images herunterladen und darin arbeiten oder man
kann alternativ einen Container selbst starten und diesen mit VSC
verbinden (â€œattachenâ€).

Beim Verbinden Ã¶ffnet VSC ein neues Fenster, welches mit dem Container
verbunden ist. Nun kann man in diesem neuen Fenster ganz normal
arbeiten, allerdings werden alle Dinge in dem Container erledigt. Man
Ã¶ffnet also Dateien in diesem Container, editiert sie im Container,
Ã¼bersetzt und testet im Container und nutzt dabei die im Container
installierten Tools. Sogar die entsprechenden VSC-Plugins kann man im
Container installieren.

Damit benÃ¶tigt man auf einem Host eigentlich nur noch VSC und Docker,
aber keine Java-Tools o.Ã¤. und kann diese Ã¼ber einen im Projekt
definierten Container (Ã¼ber ein mit versioniertes Dockerfile) nutzen.

*Anmerkung*: IntelliJ kann remote nur debuggen, d.h. das Editieren,
Ãœbersetzen, Testen lÃ¤uft lokal auf dem Host (und benÃ¶tigt dort den
entsprechenden Tool-Stack). FÃ¼r das Debuggen kann Idea das Ã¼bersetzte
Projekt auf ein Remote (SSH, Docker) schieben und dort debuggen.

Noch einen Schritt weiter geht das Projekt
[code-server](https://github.com/coder/code-server): Dieses stellt u.a.
ein Docker-Image
[codercom/code-server](https://hub.docker.com/r/codercom/code-server)
bereit, welches einen Webserver startet und Ã¼ber diesen kann man ein im
Container laufendes (angepasstes) VSC erreichen. Man braucht also nur
noch Docker und das Image und kann dann Ã¼ber den Webbrowser
programmieren. Der Projektordner wird dabei in den Container gemountet,
so dass die Dateien entsprechend zur VerfÃ¼gung stehen:

``` sh
docker run -it --name code-server -p 127.0.0.1:8080:8080 -v "$HOME/.config:/home/coder/.config" -v "$PWD:/home/coder/project" codercom/code-server:latest
```

Auf diesem Konzept setzt auch der kommerzielle Service [GitHub
Codespaces](https://github.com/features/codespaces) von GitHub auf.

<p align="right"><a href="https://youtu.be/Rs1W_rXkoNM">Demo: VSCode und Docker</a></p>

## Link-Sammlung

- [Wikipedia: Docker](https://en.wikipedia.org/wiki/Docker_(software))
- [Wikipedia: Virtuelle
  Maschinen](https://en.wikipedia.org/wiki/Virtual_machine)
- [Docker: Ãœberblick,
  Container](https://www.docker.com/resources/what-container)
- [Docker: HowTo](https://docs.docker.com/get-started/)
- [DockerHub: Suche nach fertigen
  Images](https://hub.docker.com/search?q=&type=image)
- [Docker und Java](https://docs.docker.com/language/java/)
- [Dockerfiles: Best
  Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)
- [Gitlab,
  Docker](http://git03-ifm-min.ad.hsbi.de/help/ci/docker/using_docker_images.md#overriding-the-entrypoint-of-an-image)
- [VSCode: Entwickeln in
  Docker-Containern](https://code.visualstudio.com/docs/remote/containers)
- Nickoloff ([2019](#ref-DockerInAction)) und Miell und Sayers
  ([2019](#ref-DockerInPractice))

## Wrap-Up

- Schlanke Virtualisierung mit Containern (kein eigenes OS)
- *Kein* Sandbox-Effekt

<!-- -->

- Begriffe: Docker-File vs.Â Image vs.Â Container
- Ziehen von vordefinierten Images
- Definition eines eigenen Images
- Arbeiten mit Containern: lokal, CI/CD, VSCode â€¦

## ğŸ“– Zum Nachlesen

- Ullenboom ([2021](#ref-Ullenboom2021))
- Inden ([2013](#ref-Inden2013))

> [!NOTE]
>
> <details>
>
> <summary><strong>âœ… Lernziele</strong></summary>
>
> - k2: Ich kann zwischen Containern und VMs unterscheiden
> - k1: Ich kenne typische Einsatzgebiete fÃ¼r Container
> - k2: Ich verstehe, dass Container als abgeschottete Prozesse auf dem
>   Host laufen - kein Sandbox-Effekt
> - k3: Ich kann Container von DockerHub ziehen
> - k3: Ich kann Container starten
> - k3: Ich kann eigene Container definieren und bauen
> - k3: Ich kann Container in GitLab CI/CD und/oder GitHub Actions
>   einsetzen
> - k3: Ich kann VSCode mit Containern einsetzen
>
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>ğŸ‘€ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent">
>
> <div id="ref-Inden2013" class="csl-entry">
>
> Inden, M. 2013. *Der Weg zum Java-Profi*. 2. Aufl. Dpunkt.verlag.
>
> </div>
>
> <div id="ref-DockerInPractice" class="csl-entry">
>
> Miell, I., und A. H. Sayers. 2019. *Docker in Practice*. Manning
> Publications.
>
> </div>
>
> <div id="ref-DockerInAction" class="csl-entry">
>
> Nickoloff, D. 2019. *Docker in Action*. Manning Publications.
>
> </div>
>
> <div id="ref-Ullenboom2021" class="csl-entry">
>
> Ullenboom, C. 2021. *Java ist auch eine Insel*. 16. Aufl.
> Rheinwerk-Verlag.
> <https://openbook.rheinwerk-verlag.de/javainsel/index.html>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> d448137 (lecture: update checkout examples, 2025-11-21)<br></sub></sup></p></blockquote>
